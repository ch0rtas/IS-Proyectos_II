{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"kSqbq23oP_SN"},"outputs":[],"source":["#from google.colab import files\n","#uploaded = files.upload()"]},{"cell_type":"markdown","metadata":{"id":"KwZ8Vi2XUzJ0"},"source":["# Instalación de librerias necesarias"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"pcXDT7BoU0rc"},"outputs":[],"source":["!apt-get install openjdk-8-jdk-headless -qq \u003e /dev/null\n","!wget -q https://downloads.apache.org/spark/spark-3.4.2/spark-3.4.2-bin-hadoop3.tgz\n","!tar xf spark-3.4.2-bin-hadoop3.tgz\n","!pip install -q findspark"]},{"cell_type":"markdown","metadata":{"id":"99Me12knVRwI"},"source":["# Cargamos el entorno"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YHiS6-ubVesP"},"outputs":[],"source":["import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.1-bin-hadoop3.2\"\n","import findspark\n","findspark.init(\"spark-3.4.2-bin-hadoop3\")# SPARK_HOME"]},{"cell_type":"markdown","metadata":{"id":"6xOX_Y1_Vzye"},"source":["### Importamos una serie de librería , importamos Pyspark y creamos una sesión"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dGmvYeNwV-k4"},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import findspark\n","findspark.init(\"spark-3.4.2-bin-hadoop3\")# SPARK_HOME\n","from pyspark.sql import SparkSession\n","ss = SparkSession.builder.master(\"local[*]\").getOrCreate()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n8Twcit5uEVL"},"outputs":[],"source":["from pyspark.sql.functions import *\n","from pyspark.ml.feature import VectorAssembler\n","from pyspark.ml.feature import StringIndexer"]},{"cell_type":"markdown","metadata":{"id":"lF6PIn_SLGYJ"},"source":["En el ecosistema de Apache Spark, especialmente cuando se trabaja con PySpark para tareas de Machine Learning, es común utilizar diversas transformaciones y herramientas para preparar los datos antes de entrenar modelos. Los elementos VectorAssembler y StringIndexer son dos transformadores de este tipo, provenientes del módulo pyspark.ml.feature, que juegan roles importantes en la preparación de los datos. A continuación, te explico cada uno:\n","\n","VectorAssembler\n","VectorAssembler es una transformación que combina una lista dada de columnas en una única columna vectorial. Es comúnmente utilizado para agrupar varias características en un vector, ya que muchos algoritmos de machine learning en Spark operan sobre este formato de datos. Es decir, convierte las columnas de características individuales en una columna de un vector de características, que luego puede ser utilizado por un estimador o algoritmo de ML.\n","\n","Por ejemplo, si tienes un dataset con columnas de características como \"edad\", \"altura\" y \"peso\", VectorAssembler te permite combinar estas tres columnas en una única columna que contiene vectores, donde cada vector contiene los valores de \"edad\", \"altura\" y \"peso\" para una fila particular.\n","\n","StringIndexer\n","StringIndexer es una transformación que convierte columnas de etiquetas de cadena (texto) en etiquetas de índices numéricos. Esto es especialmente útil cuando las etiquetas o las características categóricas están representadas como cadenas, ya que muchos algoritmos de machine learning prefieren trabajar con datos numéricos. StringIndexer asigna a cada cadena única un índice numérico, comenzando por 0. Esto se hace generalmente antes de pasar los datos a un algoritmo de ML para asegurarse de que las características categóricas se manejen correctamente.\n","\n","Por ejemplo, si tienes una columna con valores categóricos como \"male\" y \"female\", StringIndexer puede convertir estos valores en 0 y 1 (o 1 y 0, dependiendo de la frecuencia de cada categoría) para que puedan ser utilizados en el modelo de aprendizaje.\n","\n","Ambas transformaciones son esenciales en el proceso de preparación de datos para modelado con PySpark ML, facilitando el manejo de diferentes tipos de datos y asegurando que estén en un formato adecuado para los algoritmos de machine learning.\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MiupQwJfuH2r"},"outputs":[],"source":["irisDF= ss.read.csv(\"/content/ml_iris.csv\", inferSchema=True, header=True, nullValue='?', nanValue='?')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4C1spFC9uYQD","outputId":"e544c4fc-727f-4815-9288-b23aaba82063"},"outputs":[{"data":{"text/plain":["['Id',\n"," 'SepalLengthCm',\n"," 'SepalWidthCm',\n"," 'PetalLengthCm',\n"," 'PetalWidthCm',\n"," 'Species']"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["irisDF.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qJ_dOklSvJ3l"},"outputs":[],"source":["#irisDF = irisDF.select(col('_c0').alias('sepal_length'),\n","                       #col('_c1').alias('sepal_width'),\n","                       #col('_c2').alias('petal_length'),\n","                       #col('_c3').alias('petal_width'),\n","                       #col('_c4').alias('species'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vBIQE-MPvPmJ","outputId":"a8a96fb4-4b1c-4a77-b4fa-19d860d65975"},"outputs":[{"data":{"text/plain":["[Row(Id=1, SepalLengthCm=5.1, SepalWidthCm=3.5, PetalLengthCm=1.4, PetalWidthCm=0.2, Species='Iris-setosa')]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["irisDF.take(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dIIRKHskvoW-","outputId":"b2a93864-2e0f-4f64-d20a-13079adf938f"},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- Id: integer (nullable = true)\n"," |-- SepalLengthCm: double (nullable = true)\n"," |-- SepalWidthCm: double (nullable = true)\n"," |-- PetalLengthCm: double (nullable = true)\n"," |-- PetalWidthCm: double (nullable = true)\n"," |-- Species: string (nullable = true)\n","\n"]}],"source":["irisDF.printSchema()"]},{"cell_type":"markdown","metadata":{"id":"1jni7WJALR-C"},"source":["El método printSchema() en PySpark se utiliza para imprimir el esquema de un DataFrame, lo cual es muy útil para obtener una rápida comprensión de la estructura de los datos. El \"esquema\" define las columnas de un DataFrame, incluyendo el nombre de cada columna, su tipo de dato (como StringType, IntegerType, DoubleType, etc.), y si la columna puede contener valores nulos.\n","\n","Cuando invocas printSchema() en un DataFrame de PySpark, se muestra una descripción jerárquica del esquema en un formato fácil de leer. Por cada columna, se listarán el nombre, el tipo de dato y si es nullable (permite valores nulos) o no. Este método no devuelve un valor, sino que simplemente imprime el esquema al estándar de salida."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qfIOfGqYvymw"},"outputs":[],"source":["vectorAssembler = VectorAssembler(inputCols=['SepalLengthCm',\n","                                             'SepalWidthCm',\n","                                             'PetalLengthCm',\n","                                             'PetalWidthCm'],\n","                                  outputCol='features')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xko-KfVJwFsR","outputId":"060a76b0-4114-49ec-a2b3-6143d3e64902"},"outputs":[{"data":{"text/plain":["[Row(Id=1, SepalLengthCm=5.1, SepalWidthCm=3.5, PetalLengthCm=1.4, PetalWidthCm=0.2, Species='Iris-setosa', features=DenseVector([5.1, 3.5, 1.4, 0.2]))]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["virisDF = vectorAssembler.transform(irisDF)\n","virisDF.take(1)"]},{"cell_type":"markdown","metadata":{"id":"CsuKC8_GM4DC"},"source":["Definición: Primero, se define un VectorAssembler especificando las columnas de entrada (las características que quieres combinar) y el nombre de la columna de salida (donde se almacenarán los vectores resultantes). Las columnas de entrada pueden ser de tipos numéricos, booleanos, o vectores; el VectorAssembler los concatenará en un único vector.\n","\n","Transformación: Cuando invocas transform(irisDF) en el VectorAssembler, este procesa el DataFrame irisDF, tomando los valores de las columnas especificadas en cada fila, combinándolos en un vector, y almacenando el vector en la columna de salida especificada. Este proceso se aplica a todas las filas del DataFrame.\n","\n","Resultado: El resultado es un nuevo DataFrame que contiene todas las columnas originales de irisDF más la nueva columna agregada por VectorAssembler. Esta columna adicional contendrá los vectores que representan la combinación de las características especificadas para cada fila."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O8VkyREZwVl0","outputId":"d80dca4b-5b7d-4960-a2de-79762863711c"},"outputs":[{"data":{"text/plain":["DataFrame[Id: int, SepalLengthCm: double, SepalWidthCm: double, PetalLengthCm: double, PetalWidthCm: double, Species: string, features: vector, label: double]"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["indexer = StringIndexer(inputCol='Species', outputCol='label')\n","iVirisDF = indexer.fit(virisDF).transform(virisDF)\n","iVirisDF"]},{"cell_type":"markdown","metadata":{"id":"9Afysbd9Nof_"},"source":["Estas líneas de código utilizan StringIndexer, que es una transformación de PySpark del módulo pyspark.ml.feature, para convertir cadenas (strings) en índices numéricos. Esta transformación es útil cuando trabajas con características categóricas en formato de texto que necesitas convertir a un formato numérico para utilizar en algoritmos de machine learning que solo pueden manejar datos numéricos"]},{"cell_type":"markdown","metadata":{"id":"FdR4rOGixNHD"},"source":["### Naive Bayes Classification"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2UGlERakxEgQ","outputId":"033d9973-9b8a-425a-b577-631fb9fc089c"},"outputs":[{"data":{"text/plain":["[Row(Id=1, SepalLengthCm=5.1, SepalWidthCm=3.5, PetalLengthCm=1.4, PetalWidthCm=0.2, Species='Iris-setosa', features=DenseVector([5.1, 3.5, 1.4, 0.2]), label=0.0)]"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["iVirisDF.take(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8pM-q2zAxTk4"},"outputs":[],"source":["from pyspark.ml.classification import NaiveBayes\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vFpYSb--xdDG"},"outputs":[],"source":["splits = iVirisDF.randomSplit([0.6,0.4],1)\n","trainDF = splits[0]\n","testDF = splits[1]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6IvNjJ1yxrQ_","outputId":"126dea81-7357-46a7-d6b2-fffdd91f5d03"},"outputs":[{"data":{"text/plain":["98"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["trainDF.count()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HPjq-kr6H7aM"},"outputs":[],"source":["testDF.count()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YRgY7ZXkxvjd","outputId":"e9f82561-3164-49b9-e296-94587dc2cfef"},"outputs":[{"data":{"text/plain":["150"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["iVirisDF.count()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wWXUeWBkx3mo"},"outputs":[],"source":["nb = NaiveBayes(modelType='multinomial')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z6fn4ZzXyBF3"},"outputs":[],"source":["nbModel = nb.fit(trainDF)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kln9wQAfyFPx"},"outputs":[],"source":["predictionsDF = nbModel.transform(testDF)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sq5O6Jt7yOzi","outputId":"5b129cce-0b77-4c80-8610-53862a8cf7cb"},"outputs":[{"data":{"text/plain":["[Row(Id=1, SepalLengthCm=5.1, SepalWidthCm=3.5, PetalLengthCm=1.4, PetalWidthCm=0.2, Species='Iris-setosa', features=DenseVector([5.1, 3.5, 1.4, 0.2]), label=0.0, rawPrediction=DenseVector([-12.111, -13.4138, -14.0841]), probability=DenseVector([0.7088, 0.1926, 0.0985]), prediction=0.0)]"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["predictionsDF.take(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RQaEU9B1yXAT"},"outputs":[],"source":["evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='accuracy')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fppKY-niyYrW","outputId":"98968391-efae-42b6-8809-a578ffa60e8e"},"outputs":[{"data":{"text/plain":["0.9038461538461539"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["nbAccuracy = evaluator.evaluate(predictionsDF)\n","nbAccuracy"]},{"cell_type":"markdown","metadata":{"id":"iVvs28xVzDXv"},"source":["## Multilayer Perceptron Classification"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XM2vZjQwzGIB"},"outputs":[],"source":["# Mismo set de entrenamiento y de test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jmB8-7QYzGXB"},"outputs":[],"source":["from pyspark.ml.classification import MultilayerPerceptronClassifier"]},{"cell_type":"markdown","metadata":{"id":"cBAubjGo2uXN"},"source":["\n","\n","1. First layer has the same number of nodes as there are inputs. There are four measures, so the first layer will be four. You can then create list of layers. Set the first element to be four.\n","\n","2. Last element should have the same number of neurons as there are types of outputs. There are three types of iris species. Last row will be three.\n","\n","3. You want to have layers in between to help the multi-layer perceptron learn how to classify correctly. Insert two rows of five neurons each. There is going to be a four layer multi-layer perceptron.\n","\n","4. First layer will have four neurons, the middle two layers will have five neurons each, and then the output layer will have three neurons. One for each kind of iris species.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4-6x3-Iuzese"},"outputs":[],"source":["layers = [4,5,5,3]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0ETj8AIszewy"},"outputs":[],"source":["mlp = MultilayerPerceptronClassifier(layers=layers, seed=1)"]},{"cell_type":"markdown","metadata":{"id":"ttuUAS6WOMy_"},"source":["El parámetro layers especifica la arquitectura de la red neuronal del perceptrón multicapa, incluyendo el número de nodos en cada capa. Es una lista de enteros, donde cada entero representa el número de neuronas en una capa específica.\n","\n","El primer elemento de la lista corresponde al número de neuronas en la capa de entrada, y debe coincidir con el número de características (atributos) de tus datos de entrada.\n","Los elementos intermedios de la lista representan el número de neuronas en las capas ocultas. Puedes tener cualquier número de capas ocultas, y cada una puede tener un número diferente de neuronas.\n","El último elemento de la lista corresponde al número de neuronas en la capa de salida, que generalmente coincide con el número de clases en un problema de clasificación.\n","Por ejemplo, si layers = [4, 5, 4, 3], esto define una red neuronal con:\n","\n","4 neuronas en la capa de entrada (por ejemplo, 4 características en tus datos),\n","Dos capas ocultas con 5 y 4 neuronas respectivamente,\n","3 neuronas en la capa de salida (por ejemplo, para un problema de clasificación con 3 clases posibles).\n","Seed\n","El parámetro seed se utiliza para inicializar el generador de números aleatorios. Proporcionar un valor de seed (semilla) asegura que los resultados sean reproducibles. En el contexto de los modelos de machine learning, la inicialización aleatoria de pesos en las redes neuronales es un paso común. Al establecer una semilla específica (seed=1 en tu caso), garantizas que cada vez que ejecutes tu código, la inicialización aleatoria de los pesos sea la misma, llevando a resultados consistentes en múltiples ejecuciones.\n","\n","Esto es útil durante la fase de desarrollo y experimentación, ya que permite comparar directamente el rendimiento de diferentes configuraciones o ajustes en el modelo, sabiendo que cualquier diferencia en el rendimiento se debe a los cambios realizados y no a la variabilidad en la inicialización aleatoria de los pesos.\n","\n","En resumen, layers define la estructura de la red neuronal, y seed asegura la reproducibilidad de los resultados al inicializar de manera consistente los pesos de la red."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8cVVngKQze13"},"outputs":[],"source":["mlpModel = mlp.fit(trainDF)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KSaSSOgu3H2W"},"outputs":[],"source":["mlpPredictions = mlpModel.transform(testDF)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AKWaTRJD3LRz"},"outputs":[],"source":["mlpEvaluator = MulticlassClassificationEvaluator(metricName='accuracy')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WXkzh0ar3LUy"},"outputs":[],"source":["mlpAccuracy = mlpEvaluator.evaluate(mlpPredictions)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pVvtTMjx3LXI","outputId":"64ff14fc-a7ec-4ef8-96c5-43ee932e1ac4"},"outputs":[{"data":{"text/plain":["0.9615384615384616"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["mlpAccuracy"]},{"cell_type":"markdown","metadata":{"id":"yaaJk4ie3i0Y"},"source":["\n","## Decision Tree Classification\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PRgcnEJz3LcU"},"outputs":[],"source":["from pyspark.ml.classification import DecisionTreeClassifier"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OG2L3EwS32Mr"},"outputs":[],"source":["dt = DecisionTreeClassifier(labelCol='label', featuresCol='features')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JIze6Ut136XE"},"outputs":[],"source":["dtModel = dt.fit(trainDF)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mva5w5M936cN"},"outputs":[],"source":["dtPredictions = dtModel.transform(testDF)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SOyzTsXB36ej"},"outputs":[],"source":["dtEvaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='accuracy')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zXFE4VBm4IC5","outputId":"4cd5cdfc-ecd0-49a7-8479-166d108ab734"},"outputs":[{"data":{"text/plain":["0.9423076923076923"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["dtAccuracy = dtEvaluator.evaluate(dtPredictions)\n","dtAccuracy"]},{"cell_type":"markdown","metadata":{"id":"lEUCaHQO4SAw"},"source":["Classification Algorithms Summary\n","\n","    Naive Bayes - Works well if the attributes in your data set are what is known as independent of each other (they don't tightly correlate with each other)\n","\n","    Multilayer perceptron - Good choice when you have non-linear relationships between data elements\n","\n","    Decision Trees - Good choice for classification for many problems and decision trees are good to start with\n"]}],"metadata":{"colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}